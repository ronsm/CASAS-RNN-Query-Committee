# HAR Query Committee

This repository uses models generated by other packages to form a committee of three learners. Currently, the following datasets are supported:
* RNN models generated by the [CASAS RNN Model Generator](https://github.com/ronsm/CASAS-RNN-Model-Generator)
* Scikit-Multiflow models generated by [ARAS SKMulti Model Generator](https://github.com/ronsm/ARAS-SKMulti-Model-Generator)

It does the following tasks: (i) generates predictions from those models in a real-time simulation of one prediction per second; (ii) evaluates disagreement between those models using Kullback-Leibler (KL) divergence using the last _T_ seconds (user defined parameter) of data; and (iii) engages in dialogue with the user to label data selected for querying.

This software forms part of a system to enable simulation of a real smart home with multiple HAR classifiers, to enable experiments in active learning.

## Install / Requirements

To install, run these commands:

```
git clone https://github.com/care-group/RALT-RIoT-Booking-System-API.git
cd /directory/where/you/cloned/to
pip3 install -r requirements.txt
```

Note that if you require on an older version of TensorFlow (pre 2.0), this will upgrade your installation to the latest version if not using virtual environments.

Inside the ```query_select.py``` file, you must also configure the following parameters if you wish to change the window length or add models:
```
ROLLING_WINDOW = 30     # length of the rolling window for evaluation in seconds
NUM_LEARNERS = 3        # number of learners in the committee
```

### ARAS

You must supply the test data, models, and labels generated by the [ARAS SKMulti Model Generator](https://github.com/ronsm/ARAS-SKMulti-Model-Generator) to the program.

For the test files, you must place under the ```data/ARAS``` folder. The labels are already known to the program, so you do not need to provide a labels file. The folder should ultimately appear as follows:

```
├── data
│   ├── ARAS
│   │   └── test.csv
│   └── ...
└── ...
```

For models, you must (rename and) place under the ```models/ARAS``` folder the ```.p``` files. The prediction class is agnostic to the nature of many models in Scikit-Multiflow, and so you should rename the three models to be generic, as shown:

```
├── models
│   ├── ARAS
│   │   ├── Model1.p    # i.e. renamed from 'HoeffdingTree.p', etc.
│   │   ├── Model2.p
│   │   └── Model3.p
│   └── ...
└── ...
```

### CASAS

You must supply the test data, models, and labels generated by the [CASAS RNN Model Generator](https://github.com/ronsm/CASAS-RNN-Model-Generator) to the program.

For the test files, you must (rename and) place under the ```data/CASAS``` folder. You must also place the labels file for your chosen dataset in the same folder, e.g. for ```kyoto11``` you need ```kyoto11-labels.npy``` from the ```npy``` folder. Take this file and rename it to ```labels.py``` and place it in the ```data/CASAS``` folder. The folder should ultimately appear as follows:

```
├── data
│   ├── CASAS
│   │   ├── labels.npy
│   │   ├── x_test.csv
│   │   └── y_test.csv
│   └── ...
└── ...
```

For models, you must (rename and) place under the ```models/CASAS``` folder the ```.h5``` files as follow:
```
├── models
│   ├── CASAS
│   │   ├── biLSTM.h5
│   │   ├── CascadeLSTM.h5
│   │   └── LSTM.h5
│   └── ...
└── ...
```

## Usage

The ```query_process_control.py``` file orchestrates timing of operations. It determines when the next sample is loaded into the sample buffer and predictions made on that sample, before triggering an evaluation of the prediction buffer by the query evaluator. It uses Python's ```time.perf_counter``` to measure the time of these tasks to adjust sleep times and maintain the fixed time between samples.

### Committee Predict

Class files formatted as ```[DATASET]_committee_predict.py``` simply loads the provided models and makes predictions on sequential samples from the test set. It returns the probability predictions from each learner on the same sample of data.

### Query Select

File ```query_select.py``` has these main tasks:
* Maintain a sample buffer
* Maintains a rolling window from the head of the buffer (size determiend by ```ROLLING_WINDOW```)
* Evaluate the max disagreement (Kullback-Leibler divergence) between the learners over the fixed window

Max disagreement is found by calculating the consensus probabilities, measuring entropy of the consensus, and then by calculating the Kullback-Leibler divergence of each learner to the consensus prediction. Max disagreement is then the argmax of the learner KL divergence for each sample.

The program will generate a CSV log file in the ```logs``` folder, timestamped with the date/time that the program was run. The log file shows the class prediction from each learner, the ground truth value, the calculated max disagreement, and whether a query would be triggered.

### Dialogue Manager

The dialogue manager class in ```dialogue_manager.py``` is actived when a data point is selected for querying. It takes in the labels from the selected sample, and starts a dialogue with the user via the terminal.

It uses AIML and Spacy for NLU, and generates text using the responder class.
